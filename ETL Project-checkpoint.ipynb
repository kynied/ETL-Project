{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all .csv files from Resources folder\n",
    "file1 = \"Resources/national_2019.csv\"\n",
    "df_2019 = pd.read_csv(file1)\n",
    "\n",
    "file2 = \"Resources/national_2018.csv\"\n",
    "df_2018 = pd.read_csv(file2)\n",
    "\n",
    "file3 = \"Resources/national_2017.csv\"\n",
    "df_2017 = pd.read_csv(file3)\n",
    "\n",
    "file4 = \"Resources/national_2016.csv\"\n",
    "df_2016 = pd.read_csv(file4)\n",
    "\n",
    "file5 = \"Resources/national_2015.csv\"\n",
    "df_2015 = pd.read_csv(file5)\n",
    "\n",
    "file6 = \"Resources/national_2014.csv\"\n",
    "df_2014 = pd.read_csv(file6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 1: Combine all national records from 2014-2019 from https://www.bls.gov/\n",
    "all_dfs = [df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]\n",
    "\n",
    "df_occupationwage = pd.concat(all_dfs, axis = 0)\n",
    "df_occupationwage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 2: Life expectancy data from https://www.cdc.gov/nchs/nvss/usaleep/usaleep.html\n",
    "file_path = \"Resources/life_expectancy.csv\"\n",
    "\n",
    "life_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 3: Median Income data from https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_income\n",
    "file7 = \"Resources/median_income.csv\"\n",
    "df_medianincome = pd.read_csv(file7)\n",
    "df_medianincome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 4: Minimum Wage data from https://www.dol.gov/agencies/whd/state/minimum-wage/history\n",
    "file8 = \"Resources/Minimum Wage Data.csv\"\n",
    "df_minimumwage = pd.read_csv(file8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 1\n",
    "# Drop unwanted columns\n",
    "df_occupationwage = df_occupationwage.drop(columns = ['employment', 'emp_prse', 'hourly_pct10', 'hourly_pct25',\n",
    "                                            'hourly_median', 'hourly_pct75', 'hourly_pct90', 'annual_pct10', \n",
    "                                           'annual_pct25', 'annual_median', 'annual_pct75', 'annual_pct90'])\n",
    "\n",
    "df_occupationwage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 2\n",
    "#Only grab relevant columns\n",
    "life_df1 = life_df[['State','Life Expectancy']]\n",
    "\n",
    "#drop rows with blank values\n",
    "life_df1 = life_df1.dropna()\n",
    "\n",
    "life_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 2\n",
    "#take average of Life Expectancy in 2010-2015 by State\n",
    "life_df2 = round(life_df1.groupby('State').mean(),2)\n",
    "life_df2 = life_df2.reset_index()\n",
    "\n",
    "life_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASOURCE 2\n",
    "# Rename State column to location_name\n",
    "\n",
    "life_df2 = life_df2.rename(columns = {'State':'location_name'})\n",
    "life_df2 = life_df2.rename(columns = {'Life Expectancy':'life_expectancy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 2\n",
    "#import locations csv\n",
    "file = \"Resources/locations1.csv\"\n",
    "\n",
    "location_df = pd.read_csv(file)\n",
    "location_df = location_df.dropna()\n",
    "location_df = location_df.astype({'location_id': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_df = location_df[location_df.location_id != 0]\n",
    "#location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 2\n",
    "#left join by location_df State and drop Columns that aren't needed\n",
    "\n",
    "merged_left = pd.merge(left=location_df, right=life_df2, how='left', left_on='location_name', right_on='location_name')\n",
    "merged_left.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE 2\n",
    "#drop State Column\n",
    "life_expectancy = merged_left.drop(['location_name'], axis =1)\n",
    "life_expectancy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minimumwage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASOURCE \n",
    "df_medianincome = df_medianincome[['id', 'Year', 'Location ID', 'Median Income']]\n",
    "df_medianincome = df_medianincome.rename(columns = {'Year':'year', 'Location ID': 'location_id', 'Median Income': 'median_income'})\n",
    "df_medianincome = df_medianincome.replace([np.inf, -np.inf], np.nan)\n",
    "df_medianincome = df_medianincome.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"id\", \"year\", \"location_id\", \"median_income\"], how=\"all\")\n",
    "df_medianincome = df_medianincome.astype({'year': 'int64'})\n",
    "df_medianincome = df_medianincome.astype({'location_id': 'int64'})\n",
    "df_medianincome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Occupation Wage\")\n",
    "# print (df_occupationwage.dtypes)\n",
    "# print (\"Life Expectancy\")\n",
    "# print (life_expectancy.dtypes)\n",
    "# print (\"Location Id\")\n",
    "# print (location_df.dtypes)\n",
    "# print (\"Minimum Wage\")\n",
    "# print (df_minimumwage.dtypes)\n",
    "# print (\"Median Income\")\n",
    "# print (df_medianincome.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection\n",
    "connection_string = \"postgres:postgres@localhost:5432/ETL\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all 5 dataframes into their respective tables - only run once\n",
    "location_df.to_sql(name='locations', con=engine, if_exists='append', index=False)\n",
    "df_medianincome.to_sql(name='median_income', con=engine, if_exists='append', index=False)\n",
    "df_occupationwage.to_sql(name='occupation_wage', con=engine, if_exists='append', index=False)\n",
    "life_expectancy.to_sql(name='life_expectancy', con=engine, if_exists='append', index=False)\n",
    "df_minimumwage.to_sql(name='minimum_wage', con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
